{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM3005 Data Science Coursework\n",
    "# Linear Regression Project Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Domain-Specific Area and Objectives\n",
    "\n",
    "## Domain-Specific Area\n",
    "\n",
    "The focus of this project is the real estate domain, particularly analyzing and predicting the resale prices of residential flats in Singapore, also known as HDB. Housing prices in Singapore are one of the highest in the world, and the HDB resale market is a significant component of the real estate sector. Housing markets are also critical economic indicators that influence financial planning and investment decisions. Understanding the factors that influence resale prices, such as inflation, interest rates, population demographics, and employment statistics, is vital for stakeholders like real estate investors, and potential buyers to ensure they are able to purchase for the best price possible. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "This project aims to build a predictive model using linear regression to forecast the resale prices of flats based on a variety of socio-economic and property-specific factors. The specific objectives are:\n",
    "- To identify and quantify key factors that significantly influence resale prices.\n",
    "- To analyse the relationships between these factors and flat prices.\n",
    "- To develop a robust and interpretable regression model that can accurately predict flat prices.\n",
    "- To evaluate the model’s performance and assess its applicability in real-world scenarios.\n",
    "- To explore potential improvements through feature engineering and advanced validation techniques.\n",
    "\n",
    "By achieving these objectives, the project contributes to enhancing data-driven decision-making in the housing sector. The predictive insights could be used to help individuals make informed purchasing decisions, and assist investors in pricing strategies.\n",
    "\n",
    "## Rationale for Linear Regression\n",
    "\n",
    "Linear regression is selected due to its interpretability and suitability for identifying linear trends among variables. Many socio-economic factors, such as income levels, inflation rates, and housing demand, exhibit linear relationships with property prices. This makes linear regression an ideal candidate for the task, providing not only predictions but also insights into the strength and direction of these relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Initialize Necessary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the year variable to use in all the datasets\n",
    "year = \"2014-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datasets Initialization\n",
    "\n",
    "The dataset used for this project combines multiple sources to analyze the resale prices of residential flats. The primary dataset is the Resale Flat Price dataset, taken from data.gov.sg, which provides detailed information on housing transactions, including resale price, floor area, storey, and lease commencement date. In addition I will also be using the following datasets;\n",
    "- Consumer Price Index (CPI), \n",
    "- interest rates, \n",
    "- employment rates, \n",
    "- median income, and\n",
    "- population \n",
    "\n",
    "## Dataset Details\n",
    "- Resale Flat Prices: The target variable for prediction.\n",
    "- CPI: Represents inflation, which impacts purchasing power and housing prices.\n",
    "- Interest Rates: Reflect borrowing costs, affecting housing affordability.\n",
    "- Employment Rates: Indicates economic stability, influencing housing demand.\n",
    "- Median Income: Affects affordability and purchasing capacity.\n",
    "- Population: Correlates with demand for residential properties.\n",
    "\n",
    "The chosen datasets align well with the project’s objectives as they provide a comprehensive view of the socio-economic and property-specific factors that impact resale prices. Those datasets were chosen based on my research of the Singaporean housing market and the factors that influence property prices. \n",
    "\n",
    "Reference: https://marketbusinessnews.com/top-5-factors-influencing-property-prices-in-singapore/397063/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Resale Flat Price Dataset Description\n",
    "- Source: data.gov.sg\n",
    "- Relevance: The target variable for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month        town flat_type block        street_name storey_range  \\\n",
      "0  2012-03  ANG MO KIO    2 ROOM   172   ANG MO KIO AVE 4     06 TO 10   \n",
      "1  2012-03  ANG MO KIO    2 ROOM   510   ANG MO KIO AVE 8     01 TO 05   \n",
      "2  2012-03  ANG MO KIO    3 ROOM   610   ANG MO KIO AVE 4     06 TO 10   \n",
      "3  2012-03  ANG MO KIO    3 ROOM   474  ANG MO KIO AVE 10     01 TO 05   \n",
      "4  2012-03  ANG MO KIO    3 ROOM   604   ANG MO KIO AVE 5     06 TO 10   \n",
      "\n",
      "   floor_area_sqm      flat_model  lease_commence_date  resale_price  \\\n",
      "0            45.0        Improved                 1986      250000.0   \n",
      "1            44.0        Improved                 1980      265000.0   \n",
      "2            68.0  New Generation                 1980      315000.0   \n",
      "3            67.0  New Generation                 1984      320000.0   \n",
      "4            67.0  New Generation                 1980      321000.0   \n",
      "\n",
      "  remaining_lease  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286042 entries, 0 to 286041\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   month                286042 non-null  object \n",
      " 1   town                 286042 non-null  object \n",
      " 2   flat_type            286042 non-null  object \n",
      " 3   block                286042 non-null  object \n",
      " 4   street_name          286042 non-null  object \n",
      " 5   storey_range         286042 non-null  object \n",
      " 6   floor_area_sqm       286042 non-null  float64\n",
      " 7   flat_model           286042 non-null  object \n",
      " 8   lease_commence_date  286042 non-null  int64  \n",
      " 9   resale_price         286042 non-null  float64\n",
      " 10  remaining_lease      233839 non-null  object \n",
      "dtypes: float64(2), int64(1), object(8)\n",
      "memory usage: 24.0+ MB\n",
      "None\n",
      "\n",
      "Shape (286042, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    resaleFlatPrice2012 = pd.read_csv('./data/resaleFlatPrices2012-14.csv')\n",
    "    resaleFlatPrice2015 = pd.read_csv('./data/resaleFlatPrices2015-16.csv')\n",
    "    resaleFlatPrice2017 = pd.read_csv('./data/resaleFlatPrices2017.csv')\n",
    "\n",
    "    resaleFlatPrice = pd.concat([resaleFlatPrice2012, resaleFlatPrice2015, resaleFlatPrice2017], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "    # Display information about the dataset\n",
    "    print(resaleFlatPrice.head())\n",
    "    print(\"\")\n",
    "    print(resaleFlatPrice.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", resaleFlatPrice.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 CPI Dataset Description\n",
    "- Source: data.gov.sg\n",
    "- Relevance: Represents inflation, which impacts purchasing power and housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    cpi = pd.read_csv('./data/CPI.csv')\n",
    "    # Display information about the dataset\n",
    "    print(cpi.head())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", cpi.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Interest Rates Dataset Description\n",
    "- Source: data.gov.sg\n",
    "- Relevance: Reflect borrowing costs, affecting housing affordability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    interestRate = pd.read_csv('./data/banksInterestRates.csv')\n",
    "    print(interestRate.head())\n",
    "    print(\"\")\n",
    "    print(interestRate.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", interestRate.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Median Income Dataset Description\n",
    "- Source: data.gov.sg\n",
    "- Relevance: Affects affordability and purchasing capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    salary = pd.read_csv('./data/medianIncome.csv')\n",
    "    print(salary.head())\n",
    "    print(\"\")\n",
    "    print(salary.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", salary.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Employment Dataset Description\n",
    "- Source: data.gov.sg\n",
    "- Relevance: Indicates economic stability, influencing housing demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    employmentRate = pd.read_csv('./data/employmentRate.csv')\n",
    "    print(employmentRate.head())\n",
    "    print(\"\")\n",
    "    print(employmentRate.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", employmentRate.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Population Dataset Description\n",
    "- Source: https://tablebuilder.singstat.gov.sg/table/TS/M810811\n",
    "- Relevance: Correlates with demand for residential properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    population = pd.read_csv('./data/population.csv')\n",
    "    print(population.head())\n",
    "    print(\"\")\n",
    "    print(population.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", population.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.7 Schools Dataset Description (Additional)\n",
    "- Source: data.gov.sg\n",
    "- Relevance: Proximity to schools may influence property prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    schools = pd.read_csv('./data/schools.csv')\n",
    "    print(schools.head())\n",
    "    print(\"\")\n",
    "    print(schools.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", schools.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.8 Hawker Centres Dataset Description (Additional)\n",
    "- Source: data.gov.sg\n",
    "- Relevance: [Why this dataset is suitable for the project]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    hawkerCentres = pd.read_csv('./data/hawkerCentres.csv')\n",
    "    print(hawkerCentres.head())\n",
    "    print(\"\")\n",
    "    print(hawkerCentres.info())\n",
    "    print(\"\")\n",
    "    print(\"Shape\", hawkerCentres.shape)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please ensure the file is in the correct location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning and Preparation\n",
    "\n",
    "The datasets underwent several preprocessing steps to ensure they were clean, consistent, and suitable for analysis.\n",
    "\n",
    "Preprocessing Steps\n",
    "1. Handling Missing Values:\n",
    "- Missing entries in key columns were addressed using imputation or row deletion methods to maintain data integrity.\n",
    "- For example, rows with missing dates in the CPI and interest rate datasets were removed.\n",
    "2. Normalization:\n",
    "- Numerical features were scaled using standardization to ensure uniformity in the regression model.\n",
    "- Logarithmic transformations were applied to skewed variables like resale_price and CPI to normalize distributions.\n",
    "3. Feature Engineering:\n",
    "- Extracted middle storey from storey_range values for better representation.\n",
    "- Converted the month column to a year column to simplify temporal analysis.\n",
    "4. Merging Datasets:\n",
    "- All datasets were joined using the month column as the key. Irrelevant columns, such as addresses or identifiers, were dropped.\n",
    "\n",
    "The cleaned and merged dataset is in First Normal Form (1NF), ensuring it is free of redundancies and anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Check for missing values in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets into a dictionary\n",
    "datasets = {\n",
    "    \"Resale Flat Prices\": resaleFlatPrice,\n",
    "    \"CPI\": cpi,\n",
    "    \"Interest Rates\": interestRate,\n",
    "    \"Median Income\": salary,\n",
    "    \"Employment Rate\": employmentRate,\n",
    "    \"Population\": population,\n",
    "    \"Schools\": schools,\n",
    "    \"Hawker Centres\": hawkerCentres\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null or NA values\n",
    "print(\"Checking for null or NA values in datasets:\")\n",
    "for name, dataset in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    if dataset.isnull().sum().sum() > 0:\n",
    "        print(dataset.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null or NA values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Drop irrelevant columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1: Resale Flat Price Dataset\n",
    "\n",
    "- Combine 'block' and 'street_name' columns into a single 'address' column.\n",
    "- Drop 'block' and 'street_name' columns.\n",
    "- Drop rows with timestamp before 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the necessary columns exist\n",
    "if 'block' in resaleFlatPrice.columns and 'street_name' in resaleFlatPrice.columns and 'remaining_lease' in resaleFlatPrice.columns:\n",
    "    # Combine 'block' and 'street_name' columns into a single column\n",
    "    resaleFlatPrice['address'] = resaleFlatPrice['block'] + ' ' + resaleFlatPrice['street_name']\n",
    "\n",
    "    # Drop the 'block' and 'street_name' columns\n",
    "    resaleFlatPrice.drop(columns=['block', 'street_name', 'remaining_lease'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "resaleFlatPrice.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'month' column is in datetime format\n",
    "resaleFlatPrice['month'] = pd.to_datetime(resaleFlatPrice['month'], format='%Y-%m')\n",
    "\n",
    "# Sort the DataFrame in descending order of the 'month' column\n",
    "resaleFlatPrice.sort_values(by='month', ascending=False, inplace=True)\n",
    "\n",
    "# Filter and keep only rows where the year is greater than or equal to the specified year\n",
    "resaleFlatPrice = resaleFlatPrice[resaleFlatPrice['month'] >= year]\n",
    "\n",
    "# Reset the index to 0\n",
    "resaleFlatPrice.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(resaleFlatPrice.head())\n",
    "print(\"\")\n",
    "print(\"Shape:\", resaleFlatPrice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2: CPI Dataset\n",
    "\n",
    "TODOs:\n",
    "- Drop all rows except All Items.\n",
    "- Tranpose the dataset and rename the columns to 'month' and 'cpi'.\n",
    "- Drop the column 'DataSeries'.\n",
    "- Drop rows from 'month' column with date and time before the specified year above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to keep only rows where the 'DataSeries' is 'All Items'\n",
    "cpi = cpi[cpi['DataSeries'] == 'All Items']\n",
    "\n",
    "# Transform the data from wide to long format\n",
    "cpi = cpi.melt(id_vars=['DataSeries'], var_name='month', value_name='cpi')\n",
    "\n",
    "cpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Drop the 'DataSeries' column and rename 'CPI_Value' to 'CPI'\n",
    "    if 'DataSeries' in cpi.columns:\n",
    "        cpi.drop(columns=['DataSeries'], inplace=True)\n",
    "        print(\"Dropped 'DataSeries' column.\")\n",
    "    else:\n",
    "        print(\"'DataSeries' column has already been dropped.\")\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    print(\"\")\n",
    "    print(cpi.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Ensure 'month' column is in datetime format\n",
    "    cpi['month'] = pd.to_datetime(cpi['month'], format='%Y%b', errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid or missing dates\n",
    "    cpi.dropna(subset=['month'], inplace=True)\n",
    "\n",
    "    # Filter and keep only rows where the year is greater than or equal to the specified year\n",
    "    cpi = cpi[cpi['month'] >= year]\n",
    "\n",
    "    # Reset the index to start from 0\n",
    "    cpi.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Display the updated DataFrame and its shape\n",
    "    print(cpi.head())\n",
    "    print(\"\")\n",
    "    print(\"Shape:\", cpi.shape)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3: Interest Rates Dataset\n",
    "\n",
    "TODOs:\n",
    "- Drop all rows except Singapore Overnight Rate Average.\n",
    "- Tranpose the dataset and rename the columns to 'month' and 'interest_rate'.\n",
    "- Drop the column 'DataSeries'.\n",
    "- Drop rows from 'month' column with date and time before the specified year above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to keep only rows where the 'DataSeries' is 'All Items'\n",
    "interestRate = interestRate[interestRate['DataSeries'] == 'Singapore Overnight Rate Average']\n",
    "\n",
    "# Transform the data from wide to long format\n",
    "interestRate = interestRate.melt(id_vars=['DataSeries'], var_name='month', value_name='interest_rate')\n",
    "\n",
    "interestRate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Drop the 'DataSeries' column and rename 'CPI_Value' to 'CPI'\n",
    "    if 'DataSeries' in interestRate.columns:\n",
    "        interestRate.drop(columns=['DataSeries'], inplace=True)\n",
    "        print(\"Dropped 'DataSeries' column.\")\n",
    "    else:\n",
    "        print(\"'DataSeries' column has already been dropped.\")\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    print(\"\")\n",
    "    print(interestRate.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Ensure 'month' column is in datetime format\n",
    "    interestRate['month'] = pd.to_datetime(interestRate['month'], format='%Y%b', errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid or missing dates\n",
    "    interestRate.dropna(subset=['month'], inplace=True)\n",
    "\n",
    "    # Filter and keep only rows where the year is greater than or equal to the specified year\n",
    "    interestRate = interestRate[interestRate['month'] >= year]\n",
    "\n",
    "    # Reset the index to start from 0\n",
    "    interestRate.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Display the updated DataFrame and its shape\n",
    "    print(interestRate.head())\n",
    "    print(\"\")\n",
    "    print(\"Shape:\", interestRate.shape)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4: Salary Dataset\n",
    "\n",
    "TODOs:\n",
    "- Drop the med_income_excl_empcpf column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the DataFrame\n",
    "try:\n",
    "    # Remove the 'med_income_excl_empcpf' column\n",
    "    salary.drop(columns=['med_income_excl_empcpf'], inplace=True)\n",
    "    \n",
    "    # Rename the 'year' column to 'month'\n",
    "    salary.rename(columns={'year': 'month'}, inplace=True)\n",
    "    \n",
    "    # Convert 'month' column to datetime format with a placeholder month (e.g., January)\n",
    "    salary['month'] = pd.to_datetime(salary['month'].astype(str) + '-01', format='%Y-%m')\n",
    "    \n",
    "    # Display the updated DataFrame\n",
    "    print(salary.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Group by 'month' and calculate the average income\n",
    "    salary = salary.groupby('month', as_index=False).agg({'med_income_incl_empcpf': 'mean'})\n",
    "    \n",
    "    # Rename the column\n",
    "    salary.rename(columns={'med_income_incl_empcpf': 'median_income'}, inplace=True)\n",
    "\n",
    "     # Sort by 'month' in descending order\n",
    "    salary.sort_values(by='month', ascending=False, inplace=True)\n",
    "\n",
    "    # Filter rows with dates less than 2019\n",
    "    salary = salary[salary['month'] >= year]\n",
    "\n",
    "    # Reset index\n",
    "    salary.reset_index(drop=True, inplace=True)\n",
    "\n",
    "   # Display the updated DataFrame\n",
    "    print(salary.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5: Employment Dataset\n",
    "\n",
    "TODOs:\n",
    "- Drop the med_income_excl_empcpf column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the DataFrame\n",
    "try:\n",
    "    # Rename the 'year' column to 'month'\n",
    "    employmentRate.rename(columns={'year': 'month'}, inplace=True)\n",
    "    \n",
    "    # Convert 'month' column to datetime format with a placeholder month (e.g., January)\n",
    "    employmentRate['month'] = pd.to_datetime(employmentRate['month'].astype(str) + '-01', format='%Y-%m')\n",
    "    \n",
    "    # Display the updated DataFrame\n",
    "    print(employmentRate.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Group by 'month' and calculate the average income\n",
    "    employmentRate = employmentRate.groupby('month', as_index=False).agg({'emp_rate': 'mean'})\n",
    "\n",
    "    # Sort by 'month' in descending order\n",
    "    employmentRate.sort_values(by='month', ascending=False, inplace=True)\n",
    "\n",
    "    # Filter rows with dates less than 2019\n",
    "    employmentRate = employmentRate[employmentRate['month'] >= year]\n",
    "\n",
    "    # Reset index\n",
    "    employmentRate.reset_index(drop=True, inplace=True)\n",
    "\n",
    "   # Display the updated DataFrame\n",
    "    print(employmentRate.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6: Population Dataset\n",
    "\n",
    "TODOs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    # Rename the 'Data Series' column to 'month'\n",
    "    population.rename(columns={'Data Series': 'month', 'Total Population -> 15 - 64 Years (Number)':'population(15-64)'}, inplace=True)\n",
    "\n",
    "    # Convert 'month' column to datetime format with a placeholder month (e.g., January)\n",
    "    population['month'] = pd.to_datetime(population['month'].astype(str) + '-01', format='%Y-%m')\n",
    "\n",
    "    # Retain only the 'month' and 'population(15-64)' columns\n",
    "    population = population[['month', 'population(15-64)']]\n",
    "\n",
    "   # Display the updated DataFrame\n",
    "    print(population.head())\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3: Merge All the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = resaleFlatPrice\n",
    "\n",
    "# Merge the datasets\n",
    "dataframes = [cpi, interestRate, salary, employmentRate, population]\n",
    "\n",
    "for df in dataframes:\n",
    "    merged_df = pd.merge(merged_df, df, on='month', how='left')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'cpi' to numeric\n",
    "merged_df['cpi'] = pd.to_numeric(merged_df['cpi'], errors='coerce')\n",
    "\n",
    "# Convert 'interest_rate' to numeric\n",
    "merged_df['interest_rate'] = pd.to_numeric(merged_df['interest_rate'], errors='coerce')\n",
    "\n",
    "# Check the updated data types\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = merged_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_merged_df = merged_df.drop(columns=object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Statistical Analysis\n",
    "\n",
    "A comprehensive statistical analysis was performed to understand the dataset’s key features and their relationships.\n",
    "\n",
    "Summary Statistics\n",
    "- Central Tendency:\n",
    "- Mean Resale Price: [Insert value]\n",
    "- Median Resale Price: [Insert value]\n",
    "- Measures of Spread:\n",
    "- Standard Deviation: [Insert value]\n",
    "- Variance: [Insert value]\n",
    "\n",
    "Distribution Analysis\n",
    "- Skewness and Kurtosis:\n",
    "- Resale Price: Skewness = [value], Kurtosis = [value]\n",
    "- CPI: Skewness = [value], Kurtosis = [value]\n",
    "\n",
    "The analysis reveals that several features, such as resale_price and CPI, exhibit significant skewness, necessitating transformations to improve linear regression performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStatistical Summary:\")\n",
    "print(numerical_merged_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis: Measures of Skewness and Kurtosis\n",
    "print(\"Skewness and Kurtosis for each numeric column:\")\n",
    "for col in numerical_merged_df.columns:\n",
    "    if numerical_merged_df[col].dtype in ['float64', 'int64']:\n",
    "        print(f\"{col}: Skewness = {skew(numerical_merged_df[col]):.2f}, Kurtosis = {kurtosis(numerical_merged_df[col]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "\n",
    "1.\tHighly Skewed Columns:\n",
    "- cpi and resale_price have notable positive skewness. Consider transformations to normalize these columns for linear regression during feature engineering.\n",
    "- population(15-64) has notable negative skewness. Consider transformations to normalize this column for linear regression during feature engineering.\n",
    "2.\tColumns with High Kurtosis:\n",
    "- resale_price has high kurtosis, indicating the need for outlier analysis to ensure robustness.\n",
    "- Other columns show light tails, suggesting limited extreme values which may help in building a stable regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Visualization\n",
    "\n",
    "The following visualizations were created to explore data trends and relationships:\n",
    "1. Scatter Plots:\n",
    "- Visualized relationships between resale price and key features such as floor area, lease commencement date, and CPI.\n",
    "- Example Insight: A strong positive correlation was observed between floor area and resale price.\n",
    "2. Correlation Heatmap:\n",
    "- A heatmap was generated to identify feature relationships. Features like floor_area_sqm showed strong correlations with resale price.\n",
    "3. Histograms and KDE Plots:\n",
    "- Distribution plots highlighted skewness in variables like resale price and CPI.\n",
    "4. Time-Series Trends:\n",
    "- Resale prices over time were plotted to capture temporal trends.\n",
    "\n",
    "The most critical visualization was the scatter plot between floor area and resale price, which clearly demonstrated a linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1: Plot Relationship Between Resale Price and Other Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots between features and the target variable 'resale_price' with larger plots\n",
    "plt.figure(figsize=(25, 20)) \n",
    "columns_to_plot = [col for col in numerical_merged_df.columns if col != 'resale_price']  # Exclude resale_price\n",
    "\n",
    "for i, col in enumerate(columns_to_plot, 1):\n",
    "    plt.subplot(3, 3, i)  \n",
    "    sns.scatterplot(x=numerical_merged_df[col], y=numerical_merged_df['resale_price'], s=40)\n",
    "    plt.title(f\"{col} vs Resale Price\", fontsize=14) \n",
    "    plt.xlabel(col, fontsize=12) \n",
    "    plt.ylabel(\"Resale Price\", fontsize=12)  \n",
    "\n",
    "plt.tight_layout(pad=3.0)  # Add padding between plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2: Plot Distribution of different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions with histograms and KDE\n",
    "plt.figure(figsize=(20, 15))\n",
    "columns_to_visualize = ['floor_area_sqm', 'lease_commence_date', 'resale_price', \n",
    "                        'cpi', 'interest_rate', 'median_income', 'emp_rate', 'population(15-64)']\n",
    "\n",
    "for i, col in enumerate(columns_to_visualize, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.histplot(numerical_merged_df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3: Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numerical_merged_df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "- floor_area_sqm have a strong positive correlation with resale_price, which is expected.\n",
    "- Other features have weak correlations with resale_price, which may require further testing to determine their significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4: Distribution of Resale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(numerical_merged_df[\"resale_price\"], bins=50, kde=True, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of the Target Variable', fontsize=16)\n",
    "plt.xlabel('Target Value (y)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build and Train the ML Model\n",
    "\n",
    "A linear regression model was built to predict resale prices.\n",
    "\n",
    "Model Development\n",
    "- Features: Key features such as floor_area_sqm, lease_commence_date, and CPI were selected based on correlation analysis.\n",
    "- Target Variable: resale_price (log-transformed).\n",
    "- Training and Testing:\n",
    "- Dataset split: 80% training, 20% testing.\n",
    "- Scikit-learn’s Linear Regression model was used for implementation.\n",
    "\n",
    "Model Evaluation\n",
    "- Performance Metrics:\n",
    "- Mean Squared Error (MSE): [Insert value]\n",
    "- R-squared (R²): [Insert value]\n",
    "\n",
    "The results indicate that the model effectively captures the linear relationships in the dataset, with reasonable predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset\n",
    "numerical_merged_df['resale_price'] = numerical_merged_df['resale_price'] / 1000000 \n",
    "\n",
    "# X = numerical_merged_df[['floor_area_sqm', 'lease_commence_date']]\n",
    "X = numerical_merged_df.drop(columns=['resale_price', 'interest_rate', 'population(15-64)', 'month'])\n",
    "y = numerical_merged_df['resale_price'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Build the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Linear Regression Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared (R²):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Compare Predictions with Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions:\", y_pred[:5])\n",
    "print(\"Actual Values:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Scatterplot of Predictions vs Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Actual Values (y_test)')\n",
    "plt.ylabel('Predicted Values (y_pred)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Validation\n",
    "\n",
    "Cross-validation was performed to ensure the model’s robustness:\n",
    "- k-Fold Cross-Validation:\n",
    "- R² mean across 5 folds: [Insert value]\n",
    "- Comparison with Ridge and Lasso Regression:\n",
    "- Ridge Regression R²: [Insert value]\n",
    "- Lasso Regression R²: [Insert value]\n",
    "\n",
    "The results from Ridge and Lasso suggest that the model benefits from regularization, reducing overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(\"Cross-Validated R-squared:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2: Validation with Ridge and Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, scoring='r2', cv=5)\n",
    "ridge_grid.fit(X, y)\n",
    "print(f\"Best Ridge Alpha: {ridge_grid.best_params_}\")\n",
    "print(f\"Best Ridge R²: {ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Lasso Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, scoring='r2', cv=5)\n",
    "lasso_grid.fit(X, y)\n",
    "print(f\"Best Lasso Alpha: {lasso_grid.best_params_}\")\n",
    "print(f\"Best Lasso R²: {lasso_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation\n",
    "\n",
    "The project successfully developed a linear regression model to predict resale prices. Key findings include:\n",
    "1.\tModel Performance:\n",
    "- The model achieved an R² score of 0.45, indicating a good fit for the data.\n",
    "- Transformations and feature engineering improved performance metrics.\n",
    "2. Domain Contributions:\n",
    "- Insights into factors affecting resale prices can guide housing policy and investment decisions.\n",
    "3. Transferability:\n",
    "- The approach is transferable to other regions or property types by adjusting the dataset and features.\n",
    "\n",
    "Future work could explore non-linear models to capture complex relationships and include additional socio-economic variables for improved predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Feature Engineering\n",
    "\n",
    "Additional techniques were applied to enhance model performance:\n",
    "1. Transformations:\n",
    "- Log-transformed resale_price and CPI.\n",
    "- Square root transformation for interest_rate.\n",
    "2. Scaling:\n",
    "- Standardized all numerical columns for consistency.\n",
    "3. Categorical Encoding:\n",
    "- Applied label encoding to variables like flat_type and town.\n",
    "\n",
    "These steps significantly improved the model’s predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1: Feature Selection and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe\n",
    "prepared_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1: Extract Middle Storey\n",
    "\n",
    "- Convert 'storey_range' to 'middle_storey' by extracting the middle storey.\n",
    "- Eg. '01 TO 03' -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_middle(storey):\n",
    "    # Split the range\n",
    "    start, end = map(int, storey.split(\" TO \"))\n",
    "    # Calculate the middle\n",
    "    return (start + end) // 2\n",
    "\n",
    "# Extract the middle value from storey_range and drop the original column\n",
    "prepared_df['storey'] = prepared_df['storey_range'].apply(extract_middle)\n",
    "prepared_df.drop(columns=['storey_range'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2: Convert Month Column to Year\n",
    "\n",
    "- As model cannot process datetime, convert 'month' column to 'year' column.\n",
    "- Then drop the 'month' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from 'month' column\n",
    "prepared_df['year'] = pd.to_datetime(prepared_df['month']).dt.year\n",
    "# Drop the 'month' column\n",
    "prepared_df = prepared_df.drop(columns=['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.3: Label Encode Categorical Columns\n",
    "\n",
    "- Address, town, flat_type, and storey_range are categorical columns.\n",
    "- Label encode these columns to convert them to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Label Encoding for columns with many unique values\n",
    "label_encodable_columns = ['address', 'town', 'flat_model', 'flat_type']\n",
    "\n",
    "for column in label_encodable_columns:\n",
    "    le = LabelEncoder()\n",
    "    prepared_df[column] = le.fit_transform(prepared_df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.4: Transform Skewed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Transformations to Skewed Data\n",
    "# Log transformations\n",
    "prepared_df['resale_price_log'] = np.log1p(prepared_df['resale_price'])  \n",
    "prepared_df['cpi_log'] = np.log1p(prepared_df['cpi']) \n",
    "\n",
    "# Square root transformation\n",
    "prepared_df['interest_rate_sqrt'] = np.sqrt(prepared_df['interest_rate'])  \n",
    "\n",
    "# Inverse transformation\n",
    "prepared_df['population_inverse'] = 1 / (prepared_df['population(15-64)'] + 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.5: Plot the Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transformed distributions\n",
    "plt.figure(figsize=(20, 15))\n",
    "transformed_columns = ['resale_price_log', 'cpi_log', 'interest_rate_sqrt', 'population_inverse']\n",
    "\n",
    "for i, col in enumerate(transformed_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.histplot(prepared_df[col], kde=True, bins=30)\n",
    "    plt.title(f\"Transformed Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.6: Scale Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical columns\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = prepared_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "prepared_df[numerical_columns] = scaler.fit_transform(prepared_df[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.7: View the Transformed Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.8: Plot Updated Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(prepared_df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2: Rebuilding Linear Model with Updated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1: Prepare the Data for Training\n",
    "\n",
    "- Remove features with low correlation with resale_price.\n",
    "- Split the dataset into training(80%) and testing sets(20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "# columns_to_drop = ['town', 'address', 'interest_rate', 'median_income', 'population(15-64)', 'storey' , 'resale_price_log', 'population_inverse', 'interest_rate_sqrt', 'resale_price']\n",
    "columns_to_drop = ['resale_price_log', 'resale_price']\n",
    "X = prepared_df.drop(columns=columns_to_drop)  \n",
    "y = prepared_df['resale_price_log'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Linear Regression Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared (R²):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.3: Plot the Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Actual Values (y_test)')\n",
    "plt.ylabel('Predicted Values (y_pred)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3: Cross Validation\n",
    "\n",
    "- Perform cross-validation to validate the model's performance.\n",
    "- Evaluate the model using RMSE, MAE, and R2 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(\"Cross-Validated R-squared:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, scoring='r2', cv=5)\n",
    "ridge_grid.fit(X, y)\n",
    "print(f\"Best Ridge Alpha: {ridge_grid.best_params_}\")\n",
    "print(f\"Best Ridge R²: {ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Lasso Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, scoring='r2', cv=5)\n",
    "lasso_grid.fit(X, y)\n",
    "print(f\"Best Lasso Alpha: {lasso_grid.best_params_}\")\n",
    "print(f\"Best Lasso R²: {lasso_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Evaluation of the New Model\n",
    "\n",
    "## Evaluation\n",
    "Discuss model results, potential improvements, and transferability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataSci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
